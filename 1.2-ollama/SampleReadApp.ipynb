{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0 Initial the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"HUGGINGFACE_API_TOKEN\"]=os.getenv(\"HUGGING_FACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthasarathy.sivakasi/Library/CloudStorage/OneDrive-RackspaceInc/Projects/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'sampletextfile'}, page_content=' Date                   Details                        Merchant .City                  Amount\\n   PARTHASARATHY\\n\\n   24/06/18          WITCO   ( INDIA) PVT LTD              CHENNAI                         2,049.00 \\n   29/06/18          S Square Hospitalities                Chennai                         1,218 . 00 \\n   29/06/18          HOTEL SAVERA                          CHENNAI                           620 . 00 \\n   30/06/18          Ha. thway OERN                        Numb ai                         1,550 . 52 \\n   01/07/18          BAGHYAA HOME NEEDS                    CHENNAI                         1,100 . 00\\n   01/07/18          CYCL OGENS                            CHENNAI                       13,434.00\\n   01/07/18          SPN HOTELS PRIVATE LIM                CHENNAI                         1,800 . 00\\n   01/07/18          AMAZON SELLER SERVICE S               MUMS AI                           286 . 11\\n   03/07/18          KO ZHI IDL I                          CHENNAI                           465 . 00\\n   05/07/18          HILTON CHENNAI                        CHENNAI                       18,569.95\\n   14/07/18          KAVITHAA AGENCY                       CHENNAI                         2,911.33\\n   14/07/18          PETRO SURCHARGE WAIVER                                                   28.82 Cr\\n   14/07/18          KAVITHAA AGENCY                       CHENNAI                            21 . 58 Cr\\n   15/07/18          Ne tb anking Funds Trans              f e r                         31,000.00 Cr\\n   18/07/18          BO OKMYSHOW COM                       GURGAON                           606 . 54\\n   19/07/18          NAC JEWELLERS PRIVATE                 Chennai                       13,000.00\\n   19/07/18          SAAI FURNITURE                        CHENNAI                       11,000.00\\n   19/07/18          NAC JEWELLERS P LIMITE                D C HE NNAI                       919.00')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 1 Loading the document from the text file ##\n",
    "from langchain_community.document_loaders import TextLoader, UnstructuredPDFLoader\n",
    "loader=TextLoader(\"sampletextfile\")\n",
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/vctnxx216vj_53t96qbwg1r00000gp/T/ipykernel_2768/1399918779.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings=OllamaEmbeddings(model='nomic-embed-text:v1.5')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmbeddingsResponse(embedding=[0.5897687077522278, 0.401029109954834, -3.3032827377319336, -0.5248552560806274, 0.7503694295883179, 1.5193650722503662, -0.1255052536725998, 0.3970789909362793, 0.06761036068201065, -1.1095244884490967, 0.6922813653945923, 1.2783931493759155, 1.145704746246338, 1.0875918865203857, 0.2511359751224518, 0.293265700340271, 0.15194426476955414, -0.6336007118225098, -0.21012353897094727, -0.19572968780994415, -1.7954599857330322, -0.6283587217330933, 0.03834778070449829, -0.6681262254714966, 1.2611907720565796, 1.2775156497955322, -0.16066831350326538, -0.001951868529431522, -0.2972637116909027, -0.4810105264186859, 1.2045704126358032, -0.6384482979774475, -0.5407007932662964, -1.0363037586212158, 0.631036102771759, -1.2082654237747192, 0.6831682324409485, -0.05964048579335213, -0.1967417448759079, 0.1284455507993698, -0.014024718664586544, -0.5542796850204468, 0.3511347770690918, 0.0450400784611702, 0.5970171689987183, -0.9550229907035828, 0.5076606869697571, 1.5728405714035034, -0.7149198651313782, -0.38424253463745117, -0.66951584815979, 1.1401225328445435, -0.104322649538517, -1.946243166923523, 0.4673808813095093, 1.4350742101669312, 0.5054500102996826, -0.3424767553806305, 0.49660229682922363, 0.08488018065690994, 1.3484907150268555, 1.8001041412353516, 0.08761727064847946, 1.106224536895752, 1.301509976387024, -0.9271443486213684, -1.1388404369354248, -0.18448112905025482, 0.19364292919635773, -0.3298044502735138, 1.4759327173233032, -1.2721810340881348, 0.06182880327105522, 0.7974296808242798, -0.599319577217102, -1.1095467805862427, -1.3164925575256348, 0.41740307211875916, -0.10785061120986938, 1.0668610334396362, 0.33289310336112976, 0.43808144330978394, 0.45925793051719666, 0.22132068872451782, 1.202499508857727, 0.6128321886062622, 0.7452411651611328, -0.35310599207878113, -0.3018448054790497, -0.13288265466690063, 0.1723075956106186, -0.5784152746200562, 1.419439673423767, 0.20091919600963593, -0.447542279958725, -0.1238008439540863, -0.6141049265861511, 1.463795781135559, -1.3459190130233765, -0.6452821493148804, -1.1818938255310059, -0.5076894760131836, -0.9153273105621338, 0.7164930701255798, 1.5086371898651123, 0.530913233757019, -0.23203222453594208, -0.1805894672870636, -0.604371964931488, -0.948352038860321, 0.19233521819114685, 0.6943050026893616, -0.08655776083469391, 0.044668085873126984, -0.21479088068008423, -1.4160962104797363, 0.09280139207839966, -0.8734930753707886, 0.24530792236328125, 1.9962557554244995, 0.8864699602127075, -0.06998179852962494, 0.08276954293251038, -0.34923845529556274, -0.20885226130485535, 1.0231285095214844, -0.6087698340415955, 0.005017986986786127, 0.26514679193496704, -1.0337275266647339, -0.7352765202522278, -0.7604320049285889, -0.09461062401533127, 0.2747863233089447, 0.10679589211940765, 0.4389365315437317, -0.20060351490974426, -0.8419029116630554, 0.13484559953212738, 0.417824923992157, 0.809636116027832, 0.45347100496292114, 0.9779581427574158, -0.6686086058616638, -0.11854074895381927, -1.3558037281036377, 0.5880395770072937, -0.02099858969449997, -0.2438885122537613, -0.7186257839202881, -0.5537647604942322, -0.17979852855205536, 0.41679856181144714, 0.6463800668716431, 0.1069064810872078, -1.1119951009750366, 0.5373004674911499, -0.2011130154132843, 0.5506172180175781, 0.6678664088249207, 1.1017570495605469, 0.47951096296310425, -0.2516104280948639, 0.4726971685886383, -0.4843089282512665, -0.655470609664917, 1.119889497756958, 0.8031216263771057, 0.6616788506507874, 0.7608535289764404, -1.0930289030075073, -1.6836867332458496, -0.5536807775497437, -0.9300981163978577, -0.05213432013988495, 0.18789494037628174, 1.4197338819503784, -0.45468592643737793, 0.18808789551258087, -0.8125177025794983, -0.22709468007087708, -1.3915959596633911, 0.3032362163066864, 0.160765141248703, 0.5477924346923828, 0.04189039021730423, -1.1700950860977173, -0.8148791790008545, -0.7324281334877014, -0.5526628494262695, -0.23424947261810303, -0.5325317978858948, -1.4012359380722046, -0.928776741027832, 0.21206139028072357, -0.48625844717025757, 1.1390302181243896, 1.0099711418151855, 0.36160096526145935, 0.36570507287979126, -0.1427774876356125, -0.3128397464752197, 0.4841126799583435, -0.22297435998916626, 0.23257054388523102, 1.2749629020690918, 0.28055843710899353, 0.9312848448753357, -1.1429201364517212, 0.10017886012792587, 1.2250640392303467, -0.3910287916660309, 0.22695782780647278, -0.12689363956451416, 1.214393973350525, 0.09005336463451385, -0.9714104533195496, -0.021167879924178123, -0.2816998064517975, 1.6941709518432617, -0.46224793791770935, 0.361439973115921, 0.6453216671943665, -0.46557971835136414, 0.8195465207099915, 0.035948265343904495, -0.6304891705513, 0.14091643691062927, 0.9451439380645752, -0.3508457839488983, 0.20810431241989136, 0.2797691524028778, 0.6878581047058105, 0.7113756537437439, 0.6234050989151001, 0.8260199427604675, 0.441994845867157, 1.1982041597366333, -0.19580771028995514, -0.002997473580762744, -0.8346887826919556, 1.3399075269699097, -1.5051279067993164, 0.2655126750469208, -0.9817876219749451, 1.0001308917999268, -0.45622560381889343, -0.3881760835647583, -0.8293940424919128, -0.006437345873564482, 0.7379727959632874, 0.09620802104473114, 0.6154131293296814, 1.0294169187545776, 0.022638395428657532, -1.63799250125885, -1.2616291046142578, 0.07282305508852005, -0.06862252950668335, -1.061072587966919, -0.6642587184906006, -0.814884603023529, 0.8963246941566467, -1.5417375564575195, -1.2507671117782593, 1.1579755544662476, -0.5347692370414734, 0.5230059027671814, 0.39170053601264954, -1.517391324043274, 0.6565357446670532, 0.5547260642051697, 0.42587533593177795, 0.2591240108013153, 0.24042819440364838, -0.5761080384254456, 0.3659258186817169, -0.6129313111305237, -0.11082597821950912, 0.9324662685394287, -0.34896376729011536, -0.17901743948459625, -0.6876901388168335, -0.20361275970935822, 0.30375534296035767, 0.2944824695587158, 0.5046037435531616, 1.5885452032089233, 0.009780420921742916, 0.9866288900375366, 0.7902411222457886, 0.21618841588497162, 0.6581310629844666, 1.6161446571350098, -0.4605620503425598, 0.6946614384651184, 1.3451664447784424, 0.0629979595541954, 0.7131818532943726, -0.8065589070320129, 0.2730347514152527, 0.38128799200057983, 1.0233322381973267, 0.14369745552539825, -0.055735573172569275, 0.28124722838401794, 0.04745227470993996, 0.38485392928123474, 0.4742513597011566, -0.5915414690971375, -0.20825062692165375, 1.1944011449813843, -0.5421592593193054, 1.9761723279953003, -0.6873952746391296, 1.1692378520965576, 0.5589343905448914, -0.007876063697040081, 0.6851058006286621, 0.6832785606384277, 0.38502833247184753, -0.6958345174789429, 0.4745696485042572, -0.13342608511447906, 0.5955710411071777, 0.786594808101654, -0.897216796875, 0.9741968512535095, -0.7993289232254028, -1.0467568635940552, -0.20836733281612396, 0.5554043650627136, 0.4276931881904602, -0.39996346831321716, -1.4908500909805298, -0.1733981966972351, -0.20163409411907196, -1.1166917085647583, -0.4352191090583801, 1.1486494541168213, 1.2935147285461426, -1.763008713722229, -0.15526948869228363, -1.0935267210006714, -0.43095046281814575, -0.3217652142047882, -0.12018271535634995, -0.22791916131973267, 0.5602094531059265, -0.32539302110671997, -0.3550134599208832, 0.12897418439388275, 0.1499616652727127, -0.2579149305820465, -0.5034255981445312, 0.31460997462272644, -0.5575231909751892, 0.5337661504745483, 0.9157193899154663, -0.0031152248848229647, 0.21372263133525848, -1.0355654954910278, -0.20685894787311554, -0.2854999303817749, -0.740369439125061, 0.7576507329940796, 0.1824282705783844, 0.3826618790626526, 0.07881155610084534, -0.26041045784950256, -0.7058734893798828, -0.26799505949020386, -0.8516152501106262, 1.0905884504318237, 0.26790711283683777, 0.1929180771112442, -0.6466774344444275, -1.2446119785308838, 0.43687358498573303, 0.18851099908351898, -0.5122752785682678, 0.686400294303894, 0.0210992693901062, 0.44646671414375305, -0.016836093738675117, 0.3599487543106079, -0.4905131757259369, -1.1477385759353638, -0.46941161155700684, -0.6144462823867798, -0.25344523787498474, -1.2236851453781128, -0.3984369933605194, -0.035849425941705704, 0.35733452439308167, -1.3017303943634033, 1.1136415004730225, -0.4877961277961731, -0.45218625664711, 0.4269116520881653, -0.552293598651886, -0.7588669657707214, -0.48951274156570435, -1.2200945615768433, -0.036687735468149185, 0.6076331734657288, -0.15864256024360657, -1.529291033744812, 1.1297270059585571, 0.9371026754379272, 0.5166342258453369, 0.7954569458961487, -0.149991974234581, -2.2427256107330322, -0.007682727184146643, 0.038680922240018845, 0.434407114982605, 0.07007060945034027, 0.3694888651371002, 0.27834874391555786, 1.4765053987503052, 1.089428186416626, 0.18797153234481812, -0.4365602731704712, 0.9284190535545349, 0.3605644702911377, 0.22178128361701965, 0.5440353155136108, 0.41999584436416626, -1.067278504371643, 0.05370021611452103, -0.22123441100120544, -0.4238307774066925, -0.23382903635501862, -1.205151915550232, 0.5271085500717163, -0.3531547784805298, -0.19340188801288605, 0.2949844300746918, 1.7014329433441162, 1.1244450807571411, -1.4269648790359497, -0.5900844931602478, -1.2268223762512207, 1.4701886177062988, 2.435105800628662, 0.3019200265407562, -2.2067627906799316, -0.8144811391830444, 0.39381271600723267, -0.3712848722934723, -1.0266263484954834, 0.874154269695282, 1.6582577228546143, 1.8543038368225098, -0.12025075405836105, -0.5758376121520996, 0.4770316779613495, 1.0805275440216064, 1.7737571001052856, 0.6107203364372253, 0.14107359945774078, -0.14291070401668549, -0.07747956365346909, 0.28478503227233887, -0.2507839798927307, -0.15473617613315582, -0.1340096890926361, 0.13067373633384705, 0.6593044996261597, -1.129885196685791, -0.229105144739151, 0.3602435886859894, -0.6928382515907288, -1.2145500183105469, 0.09024586528539658, -1.4326624870300293, -0.06732188165187836, 0.7143601775169373, 1.136326551437378, 0.4706721901893616, 0.7371801733970642, -0.3103785812854767, -0.9144225716590881, -0.5679320096969604, 1.6390281915664673, 0.19185996055603027, 0.34686192870140076, 0.3314107358455658, -0.6185311675071716, 0.5657321214675903, -0.7143123149871826, 0.21740847826004028, -0.19465993344783783, 0.47017642855644226, -0.36147767305374146, 0.26886293292045593, -0.5510794520378113, 0.06578116118907928, 0.05080218240618706, 0.0499151311814785, 0.443434476852417, 0.50554358959198, 0.38530632853507996, -0.5547921061515808, 0.3874604105949402, 0.7192777991294861, -0.7912672162055969, -0.2885289192199707, 1.27923583984375, -0.49750789999961853, -1.6915215253829956, 1.5125807523727417, 0.18609493970870972, -0.07548084110021591, -1.0344690084457397, -0.3291015326976776, 0.9255189299583435, -0.5241981744766235, -0.267154723405838, 0.5529705882072449, -0.6306080222129822, -0.4152849018573761, 0.19335535168647766, -0.858905553817749, 1.117780327796936, -0.06041722372174263, -0.7607789039611816, 0.4635114073753357, 0.340896338224411, 0.0393599271774292, 0.25292515754699707, -0.6394142508506775, -0.7184588313102722, 0.6758910417556763, -0.49545809626579285, -0.29466360807418823, 0.9932271838188171, -0.003010606160387397, 0.8926358819007874, 0.021408898755908012, 0.5077707171440125, 0.45834848284721375, -0.007953961379826069, -0.26051974296569824, 0.23559515178203583, -1.4131728410720825, 0.3328774869441986, 1.3775149583816528, -0.4187055230140686, 0.6498591303825378, -0.9166403412818909, 0.5238611102104187, 0.2492443323135376, 1.1796989440917969, -0.5513163805007935, 0.13246555626392365, -0.35026323795318604, -1.1857686042785645, 0.11227547377347946, 0.1172945573925972, 0.27957382798194885, 0.19191639125347137, 0.17949268221855164, 1.1081557273864746, -1.3913708925247192, -0.028893226757645607, 0.4563068449497223, 0.37538447976112366, 0.014814331196248531, -0.03826765716075897, -0.40173813700675964, -0.5230635404586792, -0.5267274379730225, -0.14053231477737427, 0.35328859090805054, 0.2012632191181183, 0.12680940330028534, -1.057561993598938, -0.4475109279155731, 1.1775517463684082, 0.06141066551208496, 1.1569207906723022, -0.04849322885274887, -0.321944922208786, -0.46578237414360046, 0.2302062213420868, -1.125422716140747, 1.7600419521331787, -1.0151985883712769, -0.4617466926574707, -0.25863736867904663, -0.5990102887153625, -0.8202900886535645, -0.27045172452926636, -1.0811573266983032, -0.26493459939956665, -0.9877566695213318, -1.8140662908554077, -0.0716177299618721, 0.4511781930923462, -0.7351943254470825, 1.0533132553100586, -1.0212156772613525, 0.3248463273048401, 0.3820928931236267, -0.10056480020284653, -0.9651005864143372, 0.3474704921245575, -0.2946283221244812, 0.3704478442668915, -0.41389885544776917, 0.12278334051370621, -0.17615078389644623, 0.0752890557050705, -1.2881642580032349, 1.364246129989624, -0.07270301133394241, 0.7142679691314697, -2.018113851547241, -0.12973451614379883, -1.9638340473175049, 0.3710348606109619, -1.1137869358062744, 1.1645655632019043, -0.9576812386512756, -1.1601113080978394, -1.11593496799469, 0.7974935173988342, 0.7249823808670044, -0.07340013980865479, 0.820711076259613, -0.2481066882610321, -0.39861541986465454, -0.06217534467577934, 0.43108484148979187, -0.22806401550769806, 0.6407853960990906, 0.5947813391685486, 0.5154460072517395, 0.2937202453613281, 1.0155888795852661, 0.35003912448883057, -0.4350353181362152, 1.0099334716796875, -0.1566237360239029, 1.175142765045166, -0.463127464056015, 0.0375223271548748, -0.885632336139679, 1.2907462120056152, 0.7269120812416077, 0.5518621206283569, -0.9668968915939331, 0.610657274723053, -0.4810488224029541, 0.5415917634963989, 0.14942596852779388, -0.46983206272125244, -2.068848133087158, -1.0577958822250366, -0.09963180124759674, -2.1741528511047363, 0.18208584189414978, 0.6775827407836914, -0.5400879383087158, 0.2871983051300049, -0.5597323179244995, -1.7827574014663696, 0.13393017649650574, -0.8159360885620117, 0.5434409379959106, -0.4270927309989929, -0.4515126943588257, -0.015232781879603863, -0.23764996230602264, 0.4253941476345062, 0.8460085988044739, 0.5112832188606262, -0.07625929266214371, 0.9356523156166077, 0.9118743538856506, -0.30394136905670166, -0.26848697662353516, -0.30761563777923584, -0.2095385044813156, -0.41989296674728394, -0.28205424547195435, 0.6266870498657227, -2.466352701187134, 0.4394884407520294, 0.3956845700740814, -1.2578978538513184, -1.5573804378509521, 0.4919785261154175, -0.694665789604187, 0.3408265709877014, -0.6442891359329224, 0.40652433037757874, -0.4014914631843567, -1.1724189519882202, -0.11227718740701675, 0.3790077269077301, 0.8447099924087524, 0.13491255044937134, -0.9435720443725586, 0.48512977361679077, -0.4475918114185333, -0.21638889610767365, -0.08285616338253021, -0.30837544798851013, 0.5739272236824036, 0.3544886112213135, 0.9976971745491028, 0.11035926640033722, 0.37960535287857056, -0.10601507872343063, 0.2686454951763153, -0.6076741218566895, 1.0180697441101074, 0.8135896325111389, -0.3678435981273651, -0.6226511597633362, -1.4602738618850708, -0.04133961722254753, -0.41871172189712524, 0.6578444838523865, -1.4611995220184326, -0.09647014737129211, -0.6555638313293457, 0.10999874770641327, 1.0155030488967896, -0.2571275532245636, 0.5041658282279968, -0.3479175567626953, -0.8152443170547485, -0.5780041813850403, 0.14156487584114075, -0.045164335519075394, -0.3058696389198303, -1.2986983060836792, 0.24366874992847443, 0.20201422274112701, 0.3296896517276764, 0.016686515882611275, -0.4537159204483032, 0.2965695261955261, 0.5282249450683594, 1.4787954092025757, -0.36500126123428345, 0.4463295638561249, 0.22907885909080505, -0.160810187458992, 0.34802329540252686, 0.4269925653934479, 0.6880968809127808, 0.4378913342952728, -0.02233908139169216, 2.0353355407714844, -0.053642015904188156, 0.458523690700531, -0.21889768540859222, 0.34121766686439514, 0.7088749408721924, -1.1505337953567505, -0.14858579635620117, -0.5521143078804016, 0.4693329334259033])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 Creating the vector store using FAISS and Ollama Embeddings ##\n",
    "import faiss, langchain_community, ollama\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings=OllamaEmbeddings(model='nomic-embed-text:v1.5')\n",
    "ollama.embeddings(model='nomic-embed-text:v1.5', prompt='The sky is blue because of rayleigh scattering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3 Splitting the document into chunks ##\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)\n",
    "documents=text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4 Creating the vector store from the documents ##\n",
    "\n",
    "vectorstore=FAISS.from_documents(documents,embeddings)\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 Querying the vector store from the date of the transaction\n",
    "transaction_date= \"24/06/18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    (\"Summarize the amount for the transaction happened on {dateoftransaction}?\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fa9eb6bf-8742-49d5-93b0-05571234e5b9', metadata={'source': 'sampletextfile'}, page_content='18/07/18          BO OKMYSHOW COM                       GURGAON                           606 .'),\n",
       " Document(id='bc8198eb-5858-470b-9d44-9c3ce897ddda', metadata={'source': 'sampletextfile'}, page_content='Date                   Details                        Merchant .City                  Amount'),\n",
       " Document(id='1ab30097-85a4-4b0a-93af-0857e7351ca9', metadata={'source': 'sampletextfile'}, page_content='01/07/18          AMAZON SELLER SERVICE S               MUMS AI                           286 .')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=vectorstore.similarity_search(\"get me the transaction date on 24/06/18\",k=3)\n",
    "docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bc8198eb-5858-470b-9d44-9c3ce897ddda', metadata={'source': 'sampletextfile'}, page_content='Date                   Details                        Merchant .City                  Amount'),\n",
       " Document(id='fa9eb6bf-8742-49d5-93b0-05571234e5b9', metadata={'source': 'sampletextfile'}, page_content='18/07/18          BO OKMYSHOW COM                       GURGAON                           606 .'),\n",
       " Document(id='f020ccfd-b6a2-4151-9627-34a9ba8a02d2', metadata={'source': 'sampletextfile'}, page_content='465 . 00')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3})\n",
    "docs=retriever.invoke({\"question\":\"get me the transaction date on 24/06/18\"})\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(\n",
    "    model=\"gemma:2b\",\n",
    "    temperature=0.9,\n",
    "    num_predict=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is a question that has occupied philosophers and thinkers for centuries. It is a question that each individual must answer for themselves, as their own experiences, beliefs, and values shape their understanding of what life is about.\n",
      "\n",
      "There is no single, correct answer to this question, and different perspectives exist. Some people find meaning in their relationships, others in their work, and still others in their pursuit of personal growth. Ultimately, the meaning of life is whatever brings you the most happiness, fulfillment, and meaning in your life.\n",
      "\n",
      "Here are some different approaches to finding meaning:\n",
      "\n",
      "* **Personal growth:** Focus on self-discovery, learning new skills, and challenging yourself to grow both intellectually and personally.\n",
      "* **Relationships:** Build meaningful and fulfilling relationships with others who share your values and interests.\n",
      "* **Service to others:** Find a way to contribute to your community and leave a positive impact on the world.\n",
      "* **Pursuit of passions:** Follow your interests and do what you enjoy doing.\n",
      "* **Spiritual exploration:** Explore your beliefs and find a sense of meaning and purpose within a religious framework.\n",
      "* **Meaning in relationships:** Create meaningful connections with others and find fulfillment in sharing experiences and supporting one another.\n",
      "\n",
      "It is important to remember\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The meaning of life is \"\n",
    "response = model.invoke(input_text)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating promt with the context from the vector store ## Retrieval Chain, Document chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the document chain ##\n",
    "document_chain=create_stuff_documents_chain(llm=model, prompt=prompt, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the retrieval chain ##\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "retriever=vectorstore.as_retriever()\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'get me the transaction date on 24/06/18',\n",
       " 'context': [Document(id='fa9eb6bf-8742-49d5-93b0-05571234e5b9', metadata={'source': 'sampletextfile'}, page_content='18/07/18          BO OKMYSHOW COM                       GURGAON                           606 .'),\n",
       "  Document(id='bc8198eb-5858-470b-9d44-9c3ce897ddda', metadata={'source': 'sampletextfile'}, page_content='Date                   Details                        Merchant .City                  Amount'),\n",
       "  Document(id='1ab30097-85a4-4b0a-93af-0857e7351ca9', metadata={'source': 'sampletextfile'}, page_content='01/07/18          AMAZON SELLER SERVICE S               MUMS AI                           286 .'),\n",
       "  Document(id='4574d5c7-c025-4f52-b0a1-adfbfa133ebd', metadata={'source': 'sampletextfile'}, page_content='24/06/18          WITCO   ( INDIA) PVT LTD              CHENNAI                         2,049.00')],\n",
       " 'answer': 'I am unable to access the context and cannot generate an answer based on the provided context.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\"input\":\"get me the transaction date on 24/06/18\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=model, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= llm_chain.invoke({\"dateoftransaction\": transaction_date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'India', 'text': 'The capital of India is New Delhi. It is the political and administrative center of the country.'}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating promt with the context from the vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Prompt must accept context as an input variable. Received prompt with input variables: ['city']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m document_chain = \u001b[43mcreate_stuff_documents_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-RackspaceInc/Projects/.venv/lib/python3.12/site-packages/langchain_classic/chains/combine_documents/stuff.py:84\u001b[39m, in \u001b[36mcreate_stuff_documents_chain\u001b[39m\u001b[34m(llm, prompt, output_parser, document_prompt, document_separator, document_variable_name)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_stuff_documents_chain\u001b[39m(\n\u001b[32m     26\u001b[39m     llm: LanguageModelLike,\n\u001b[32m     27\u001b[39m     prompt: BasePromptTemplate,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     document_variable_name: \u001b[38;5;28mstr\u001b[39m = DOCUMENTS_KEY,\n\u001b[32m     33\u001b[39m ) -> Runnable[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]:\n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Create a chain for passing a list of Documents to a model.\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[43m_validate_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_variable_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     _document_prompt = document_prompt \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_DOCUMENT_PROMPT\n\u001b[32m     86\u001b[39m     _output_parser = output_parser \u001b[38;5;129;01mor\u001b[39;00m StrOutputParser()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-RackspaceInc/Projects/.venv/lib/python3.12/site-packages/langchain_classic/chains/combine_documents/base.py:32\u001b[39m, in \u001b[36m_validate_prompt\u001b[39m\u001b[34m(prompt, document_variable_name)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m document_variable_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prompt.input_variables:\n\u001b[32m     28\u001b[39m     msg = (\n\u001b[32m     29\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPrompt must accept \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocument_variable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as an input variable. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived prompt with input variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt.input_variables\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Prompt must accept context as an input variable. Received prompt with input variables: ['city']"
     ]
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(llm=model,prompt=prompt)\n",
    "document_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PromptTemplate' from 'langchain' (/Users/parthasarathy.sivakasi/Library/CloudStorage/OneDrive-RackspaceInc/Projects/.venv/lib/python3.12/site-packages/langchain/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## prompt template\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate   \n\u001b[32m      3\u001b[39m template=\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33mYou are a helpful assistant that helps people find information.\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mUse the following pieces of context to answer the question at the end.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33mHelpful Answer:\u001b[39m\u001b[33m\"\"\"\u001b[39m  \n\u001b[32m     10\u001b[39m prompt = PromptTemplate(template=template, input_variables=[\u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PromptTemplate' from 'langchain' (/Users/parthasarathy.sivakasi/Library/CloudStorage/OneDrive-RackspaceInc/Projects/.venv/lib/python3.12/site-packages/langchain/__init__.py)"
     ]
    }
   ],
   "source": [
    "## prompt template\n",
    "from langchain import PromptTemplate   \n",
    "template=\"\"\"\n",
    "You are a helpful assistant that helps people find information.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"  \n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics tracked on their usage graph.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"LangSmith has two usage limits: total traces and extended\",\n",
    "    \"context\":[Document(page_content=\"LangSmith has two usage limits: total traces and extended traces. These correspond to the two metrics we've been tracking on our usage graph. \")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023EF4D513F0>), config={'run_name': 'retrieve_documents'})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), config={'run_name': 'format_inputs'})\n",
       "            | ChatPromptTemplate(input_variables=['context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'))])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023FB8A1DB10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023FB87D31F0>, model_name='gpt-4o', openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "            | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "  }), config={'run_name': 'retrieval_chain'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To set usage limits in LangSmith, navigate to **Settings -> Usage and Billing -> Usage configuration**. There, you will find a table at the bottom of the page that allows you to set usage limits per workspace. The two types of limits you can set are **total traces** and **extended retention traces**, each with an associated cost estimate.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response form the LLM\n",
    "response=retrieval_chain.invoke({\"input\":\"LangSmith has two usage limits: total traces and extended\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith has two usage limits: total traces and extended',\n",
       " 'context': [Document(page_content='use usage limits to prevent future overspend.LangSmith has two usage limits: total traces and extended retention traces. These correspond to the two metrics we\\'ve\\nbeen tracking on our usage graph. We can use these in tandem to have granular control over spend.To set limits, we navigate back to Settings -> Usage and Billing -> Usage configuration. There is a table at the\\nbottom of the page that lets you set usage limits per workspace. For each workspace, the two limits appear, along\\nwith a cost estimate:Lets start by setting limits on our production usage, since that is where the majority of spend comes from.Setting a good total traces limit\\u200bPicking the right \"total traces\" limit depends on the expected load of traces that you will send to LangSmith. You should\\nclearly think about your assumptions before setting a limit.For example:Current Load: Our gen AI application is called between 1.2-1.5 times per second, and each API request has a trace associated with it,', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       "  Document(page_content=\"more than 10% of traces.noteIf you want to keep a subset of traces for longer than 400 days for data collection purposes, you can create another run\\nrule that sends some runs to a dataset of your choosing. A dataset allows you to store the trace inputs and outputs (e.g., as a key-value dataset),\\nand will persist indefinitely, even after the trace gets deleted.See results after 7 days\\u200bWhile the total amount of traces per day stayed the same, the extended data retention traces was cut heavily.This translates to the invoice, where we've only spent about $900 in the last 7 days, as opposed to $2,000 in the previous 4.\\nThat's a cost reduction of nearly 75% per day!Optimization 2: limit usage\\u200bIn the previous section, we managed data retention settings to optimize existing spend. In this section, we will\\nuse usage limits to prevent future overspend.LangSmith has two usage limits: total traces and extended retention traces. These correspond to the two metrics we've\", metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       "  Document(page_content='and Invoices.Usage Graph\\u200bThe usage graph lets us examine how much of each usage based pricing metric we have consumed lately. It does not directly show\\nspend (which we will see later on our draft invoice).We can navigate to the Usage Graph under Settings -> Usage and Billing -> Usage Graph.We see in the graph above that there are two usage metrics that LangSmith charges for:LangSmith Traces (Base Charge)LangSmith Traces (Extended Data Retention Upgrades).The first metric tracks all traces that you send to LangSmith. The second tracks all traces that also have our Extended 400 Day Data Retention.\\nFor more details, see our data retention conceptual docs. Notice that these graphs look\\nidentical, which will come into play later in the tutorial.LangSmith Traces usage is measured per workspace, because workspaces often represent development environments (as in our example),', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}),\n",
       "  Document(page_content='defaults for new projectsChange project level retention defaultsCOMING SOON Keep around a percentage of traces for extended data retentionSee results after 7 daysOptimization 2: limit usageSetting a good total traces limitCutting maximum spend with an extended data retention limitSet dev/staging limits and view total spent limit across workspacesSummaryCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/tutorials/Administrators/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ðŸ¦œï¸ðŸ› ï¸ LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'})],\n",
       " 'answer': 'To set usage limits in LangSmith, navigate to **Settings -> Usage and Billing -> Usage configuration**. There, you will find a table at the bottom of the page that allows you to set usage limits per workspace. The two types of limits you can set are **total traces** and **extended retention traces**, each with an associated cost estimate.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
